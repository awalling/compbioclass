{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from six import iteritems\n",
    "from bin.Loader import Loader\n",
    "from bin.Feature import Feature\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7157 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the viral and GTA fasta files \n",
    "gta_file = \"data/training/gta/3_gta.faa\"\n",
    "viral_file = \"data/training/viral/3_viral.faa\"\n",
    "gta_profs = Loader.load(gta_file, \"GTA\")\n",
    "viral_profs = Loader.load(viral_file, \"virus\")\n",
    "\n",
    "kmer_size = 3\n",
    "PSE_WEIGHT = 0.05\n",
    "LAM = 3\n",
    "PSEAAC = True\n",
    "PHYSICOCHEM = True\n",
    "\n",
    "# make kmer features \n",
    "features = Feature(gta_profs.profiles+viral_profs.profiles)\n",
    "features.make_kmer_dict(kmer_size);\n",
    "features.kmer_feat()\n",
    "\n",
    "# make pseudo amino acid composition features \n",
    "if PSEAAC:\n",
    "    print(len(features.profiles[1].features), \"\\n\")\n",
    "    features.pseaac(lam=LAM, weight=PSE_WEIGHT)\n",
    "    #print(len(features.profiles[1].features), \"\\n\")\n",
    "\n",
    "# make physico-chemical properties features \n",
    "if PHYSICOCHEM:\n",
    "    features.physicochem()\n",
    "    #print(len(features.profiles[1].features), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(834, 7199) (834,)\n"
     ]
    }
   ],
   "source": [
    "# put together the final training dataset\n",
    "num_to_label_dict = {-1:\"GTA\", 1:\"virus\"}\n",
    "label_to_num_dict = {v:k for k,v in iteritems(num_to_label_dict)}\n",
    "xs, ys = [], []\n",
    "profiles = gta_profs.profiles + viral_profs.profiles\n",
    "for i, profile in enumerate(profiles):\n",
    "    xs.append(profile.features)\n",
    "    ys.append(label_to_num_dict[profile.label])\n",
    "Xtrain = np.array(xs)\n",
    "Ytrain = np.array(ys).astype(Xtrain.dtype)\n",
    "print(Xtrain.shape, Ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set up the test dataset \n",
    "test_file = \"example_run/g3_example.faa\"\n",
    "test_profs = Loader.load(test_file)\n",
    "features.kmer_feat(test_profs)\n",
    "if PSEAAC:\n",
    "    features.pseaac(lam=LAM, weight=PSE_WEIGHT, profiles=test_profs)\n",
    "if PHYSICOCHEM:\n",
    "    features.physicochem(profiles=test_profs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 7199)\n"
     ]
    }
   ],
   "source": [
    "xs = []\n",
    "for profile in test_profs:\n",
    "    xs.append(profile.features)\n",
    "Xtest = np.array(xs)\n",
    "print(Xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train SVM classifier \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SV classifier with linear kernel\n",
    "linear_sv_clf = SVC(C=10000, kernel='linear')\n",
    "linear_sv_clf.fit(Xtrain, Ytrain);\n",
    "\n",
    "# SV classifier with RBF kernel \n",
    "rbf_sv_clf = SVC(C=10000, kernel='rbf')\n",
    "rbf_sv_clf.fit(Xtrain, Ytrain);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GTA', 'GTA', 'virus', 'virus', 'virus']\n"
     ]
    }
   ],
   "source": [
    "print([num_to_label_dict[i] for i in linear_sv_clf.predict(Xtest)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GTA', 'GTA', 'virus', 'virus', 'virus']\n"
     ]
    }
   ],
   "source": [
    "print([num_to_label_dict[i] for i in linear_sv_clf.predict(Xtest)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set upRandom Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.999 Stdev(0.003)\n"
     ]
    }
   ],
   "source": [
    "#evaluate random forest algorithm for classification\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import arange\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#define the model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "#evaluate the model\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, Xtrain, Ytrain, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\n",
    "#report performance\n",
    "print('Accuracy: %.3f Stdev(%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GTA', 'GTA', 'virus', 'virus', 'virus']\n"
     ]
    }
   ],
   "source": [
    "model.fit(Xtrain, Ytrain)\n",
    "model.predict(Xtest)\n",
    "print([num_to_label_dict[i] for i in model.predict(Xtest)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explore random forest number of features effect on performance\n",
    "\n",
    "#get a list of models to evaluate\n",
    "def get_models():\n",
    "    models=dict()\n",
    "    #explore number of features from 1 to 7\n",
    "    for i in range(1,25):\n",
    "        models[str(i)] = RandomForestClassifier(max_features=i)\n",
    "    return models\n",
    "\n",
    "#evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    #define the evaluation procedure\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    #evaluate the model and collect the results\n",
    "    scores=cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "\n",
    "#get the models to evaluate\n",
    "models = get_models()\n",
    "\n",
    "#evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    #evaluate the model\n",
    "    scores = evaluate_model(model, Xtrain, Ytrain)\n",
    "    #store the results\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    #summarize the performance along the way\n",
    "    print ('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "    \n",
    "#plot model performance for comparison\n",
    "\n",
    "bp=plt.boxplot(results, labels=names, showmeans=True)\n",
    "\n",
    "\n",
    "plt.title('Effect of Number of Features on Accuracy')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.savefig('features_accuracy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explore random forest number of trees effect on performance\n",
    "\n",
    "#get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    #define number of trees to consider\n",
    "    n_trees = [1,2,3,4,5,6,7,8,9, 10] #, 50, 100, 500, 1000]\n",
    "    for n in n_trees:\n",
    "        models[str(n)] = RandomForestClassifier(n_estimators=n)\n",
    "    return models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    # define the evaluation procedure\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    # evaluate the model and collect the results\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "\n",
    "#get the models\n",
    "\n",
    "models = get_models()\n",
    "\n",
    "#evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    #evaluate the model\n",
    "    scores = evaluate_model(model, Xtrain, Ytrain)\n",
    "    \n",
    "    #store the results\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    \n",
    "    #summarize the performance along the way\n",
    "    print('>%s %.3f  (%.3f)' % (name, mean(scores), std(scores)))\n",
    "    \n",
    "#plot model performance\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "\n",
    "\n",
    "plt.title('Effect of Number of Trees on Accuracy')\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.savefig('numberoftrees_accuracy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explore random forest tree depth effect on performance\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    # consider tree depths from 1 to 7 and None=full\n",
    "    depths = [i for i in range(1,8)] + [None]\n",
    "    for n in depths:\n",
    "        models[str(n)] = RandomForestClassifier(max_depth=n)\n",
    "    return models\n",
    " \n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    # define the evaluation procedure\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    # evaluate the model and collect the results\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    " \n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    # evaluate the model\n",
    "    scores = evaluate_model(model, Xtrain, Ytrain)\n",
    "    # store the results\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    # summarize the performance along the way\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "\n",
    "\n",
    "plt.title('Effect of Tree Depth on Accuracy')\n",
    "plt.xlabel('Tree Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.savefig('treedepth_accuracy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: 1.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#putting it together...\n",
    "\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "#define the model\n",
    "model = RandomForestClassifier(max_features=18, n_estimators=50, class_weight='balanced')\n",
    "\n",
    "#evaluate the model\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, Xtrain, Ytrain, scoring='roc_auc', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\n",
    "model.fit(Xtrain, Ytrain)\n",
    "model.predict(Xtest)\n",
    "\n",
    "plot_roc_curve(model, Xtrain, Ytrain)\n",
    "plt.savefig('ROCAUC.png')\n",
    "#report performance\n",
    "print('Mean ROC AUC: %.3f' % (mean(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#BLAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "from Bio.Blast.Applications import NcbiblastpCommandline\n",
    "from Bio.Blast import NCBIXML\n",
    "from Bio import SeqIO\n",
    "import argparse\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd \n",
    "from bin.filter_extract_fasta_ch import extract_fasta\n",
    "from bin.Loader import Loader\n",
    "from bin.Weight import Weight\n",
    "from bin.Feature import Feature\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import arange\n",
    "from six import iteritems\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict():\n",
    "    \"\"\"function to create a dictionary with info associated with each gta gene, \n",
    "    so that when there is a blast hit we can identify which gta gene it is a homolog to\"\"\"\n",
    "    folder = \"data/training/gta/\"\n",
    "    folder2 = \"data/training/viral/\"\n",
    "    master_dict = {}\n",
    "    for child in os.listdir(folder):\n",
    "        if child[-3:] == \"faa\":\n",
    "            file = os.path.join(folder,child)\n",
    "            gene = child.split('_')[0]\n",
    "            glist = []\n",
    "            f = open(file)\n",
    "            content = f.readlines()\n",
    "            for line in content:\n",
    "                if line[0] == '>':\n",
    "                    words = line.split()\n",
    "                    ID = words[0][1:]\n",
    "                    glist.append(ID)\n",
    "\n",
    "            master_dict[gene] = glist\n",
    "\n",
    "    for child in os.listdir(folder2):\n",
    "        if child[-3:] == \"faa\":\n",
    "            file = os.path.join(folder2,child)\n",
    "            gene = child.split('_')[0]\n",
    "            f = open(file)\n",
    "            content = f.readlines()\n",
    "            for line in content:\n",
    "                if line[0] == '>':\n",
    "                    words = line.split()\n",
    "                    ID = words[0][1:]\n",
    "                    master_dict[gene].append(ID)\n",
    "\n",
    "    return master_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_wrapper(querydir, queryname, outdir):\n",
    "\n",
    "\n",
    "    my_dict = get_dict()\n",
    "\n",
    "    query_file= querydir + \"/\" + queryname\n",
    "\n",
    "\n",
    "    out_dir=outdir\n",
    "    \n",
    "    #output file (btab) from the blast against GTA db\n",
    "    blast_out = out_dir +\"/blast\"+queryname + \".out\"\n",
    "    #special blast outformat parameters\n",
    "    outformat = \"6 qseqid sstart send sframe sseqid pident qlen slen length mismatch gapopen qstart qend evalue bitscore\"\n",
    "    #run blast search using database of viral and GTA training set\n",
    "    blastp_cline = NcbiblastpCommandline(query=query_file, db=\"data/GTA_db/GTA_viral\", evalue=0.001, outfmt=outformat, out=blast_out, num_threads=2,dbsize=10000000)\n",
    "    blastp_cline\n",
    "    stdout,stderr = blastp_cline()\n",
    "    result = open(blast_out)\n",
    "    lines = result.readlines()\n",
    "    result.close()\n",
    "    handle_in = open(query_file)\n",
    "    #keep track of which sequences did not have a GTA homolog\n",
    "    no_hit_list = []\n",
    "    for record in SeqIO.parse(handle_in, \"fasta\"):\n",
    "        no_hit_list.append(record.id)\n",
    "    handle_in.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    #continue if blast search had results\n",
    "    if len(lines) > 0:\n",
    "        #file to store the results of running GTA_Hunter\n",
    "        results_file = out_dir + \"/results\" +queryname+\".out\"\n",
    "\n",
    "        #run script to extract fasta files from blast search\n",
    "        genes_found = extract_fasta(blast_out,query_file,out_dir,my_dict,queryname)\n",
    "        \n",
    "\n",
    "\n",
    "        if len(genes_found) > 0:\n",
    "            results_handle = open(results_file, 'w')\n",
    "            \n",
    "            \n",
    "            # for each GTA gene that had homologs, run GTA Hunter\n",
    "            for gene in genes_found:\n",
    "                \n",
    "                \n",
    "                out_faa = out_dir + \"/gta_homolog_\" +gene+queryname+\".faa\"\n",
    "                \n",
    "                results_handle.write(str(out_faa)+\"\\n\")\n",
    "                \n",
    "                print(out_faa)\n",
    "                \n",
    "            \n",
    "    \n",
    "                #get training files corresponding to the gene identified\n",
    "                gta_file = \"data/training/gta/\" + gene + \"_gta.faa\"\n",
    "                viral_file = \"data/training/viral/\" + gene + \"_viral.faa\"\n",
    "                gta_weight = \"data/training/gta/\" + gene + \"_gta.dist\"\n",
    "                virus_weight = \"data/training/viral/\" + gene + \"_viral.dist\"\n",
    "                \n",
    "                \n",
    "                gta_profs = Loader.load(gta_file, \"GTA\")\n",
    "                viral_profs = Loader.load(viral_file, \"virus\")\n",
    "                kmer_size = 3\n",
    "                PSE_WEIGHT = 0.05\n",
    "                LAM = 3\n",
    "                PSEAAC = True\n",
    "                PHYSICOCHEM = True\n",
    "\n",
    "                # make kmer features \n",
    "                features = Feature(gta_profs.profiles+viral_profs.profiles)\n",
    "                features.make_kmer_dict(kmer_size);\n",
    "                features.kmer_feat()\n",
    "\n",
    "                # make pseudo amino acid composition features \n",
    "                if PSEAAC:\n",
    "                    print(len(features.profiles[1].features), \"\\n\")\n",
    "                    features.pseaac(lam=LAM, weight=PSE_WEIGHT)\n",
    "    \n",
    "\n",
    "                # make physico-chemical properties features \n",
    "                if PHYSICOCHEM:\n",
    "                    features.physicochem()\n",
    "                    \n",
    "                num_to_label_dict = {-1:\"GTA\", 1:\"virus\"}\n",
    "                label_to_num_dict = {v:k for k,v in iteritems(num_to_label_dict)}\n",
    "                xs, ys = [], []\n",
    "                profiles = gta_profs.profiles + viral_profs.profiles\n",
    "                for i, profile in enumerate(profiles):\n",
    "                    xs.append(profile.features)\n",
    "                    ys.append(label_to_num_dict[profile.label])\n",
    "                Xtrain = np.array(xs)\n",
    "                Ytrain = np.array(ys).astype(Xtrain.dtype)\n",
    "                #print(Xtrain.shape, Ytrain.shape)\n",
    "                \n",
    "                \n",
    "\n",
    "                test_profs = Loader.load(out_faa)\n",
    "                features.kmer_feat(test_profs)\n",
    "                if PSEAAC:\n",
    "                    features.pseaac(lam=LAM, weight=PSE_WEIGHT, profiles=test_profs)\n",
    "                if PHYSICOCHEM:\n",
    "                    features.physicochem(profiles=test_profs)\n",
    "                    \n",
    "                xs = []\n",
    "                for profile in test_profs:\n",
    "                    xs.append(profile.features)\n",
    "                Xtest = np.array(xs)\n",
    "                #print(Xtest.shape)\n",
    "                \n",
    "                linear_sv_clf = SVC(C=10000, kernel='linear')\n",
    "                linear_sv_clf.fit(Xtrain, Ytrain);\n",
    "\n",
    "                # SV classifier with RBF kernel \n",
    "                rbf_sv_clf = SVC(C=10000, kernel='rbf')\n",
    "                rbf_sv_clf.fit(Xtrain, Ytrain);\n",
    "                #print(\"THE SVM CLASSIFIER PREDICTS:\", [num_to_label_dict[i] for i in linear_sv_clf.predict(Xtest)])\n",
    "                results_handle.write(\"THE SVM CLASSIFIER PREDICTS:\"+str([num_to_label_dict[i] for i in linear_sv_clf.predict(Xtest)])+\"\\n\")\n",
    "                \n",
    "                #Random Forest Classifier\n",
    "                RFClassifier = RandomForestClassifier(max_features=18, n_estimators=50, class_weight='balanced')\n",
    "                RFClassifier.fit(Xtrain, Ytrain)\n",
    "                RFClassifier.predict(Xtest)\n",
    "                #print(\"THE RANDOM FOREST CLASSIFIER PREDICTS:\",[num_to_label_dict[i] for i in RFClassifier.predict(Xtest)])\n",
    "                results_handle.write(\"THE RANDOM FOREST CLASSIFIER PREDICTS:\"+str([num_to_label_dict[i] for i in RFClassifier.predict(Xtest)])+\"\\n\")\n",
    "\n",
    "            results_handle.close()\n",
    "            #close original query file and GTA_Hunter results file\n",
    "            results_handle = open(results_file)\n",
    "            lines = results_handle.readlines()\n",
    "\n",
    "            #update the list of sequences that did not have a GTA homolog\n",
    "            for line in lines:\n",
    "                words = line.split()\n",
    "                if words[0] != \"Gene\":\n",
    "                    if words[0][1:] in no_hit_list:\n",
    "                        no_hit_list.remove(words[0][1:])\n",
    "            results_handle.close()            \n",
    "                \n",
    "                \n",
    "    else:\n",
    "        #if the blast.out file is empty\n",
    "        print(\"Sorry, no GTA homologs were found\")\n",
    "\n",
    "    #write out a list of gene IDs of genes that were not homologs to any GTA gene \n",
    "    no_hit_file = out_dir+ \"/no_homologs\" +queryname+\".txt\"\n",
    "    no_hit_handle = open(no_hit_file,'w')\n",
    "    for nohit in no_hit_list:\n",
    "        no_hit_handle.write(nohit + '\\n')\n",
    "    no_hit_handle.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_wrapper(\"Citro_Eryth\",\"NZ_WTZA01000001.faa\", \"Citro_Eryth/Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Citro_Eryth=\"/Users/alexandrawalling/Dropbox (AMNH)/ML_Project/GTA-Hunter-v1-master-2/Citro_Eryth\"\n",
    "\n",
    "for file in os.listdir(Citro_Eryth):\n",
    "    print(file)\n",
    "    run_wrapper(Citro_Eryth, file, \"Citro_Eryth/Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alphaproteobacteria = \"/Users/alexandrawalling/Dropbox (AMNH)/ML_Project/GTA-Hunter-v1-master-2/ncbi-genomes-2021-05-18\"\n",
    "\n",
    "\n",
    "for file in os.listdir(Alphaproteobacteria):\n",
    "    run_wrapper(Alphaproteobacteria, file, \"/Users/alexandrawalling/Dropbox (AMNH)/ML_Project/GTA-Hunter-v1-master-2/ncbi-genomes-2021-05-18/Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
